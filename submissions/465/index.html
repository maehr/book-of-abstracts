<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes">

<meta name="author" content="Dominic Weber">
<meta name="dcterms.date" content="2024-07-23">
<meta name="keywords" content="Machine Learning, Methodology, Epistemology, Facticity, Evaluation">

<title>On the Historiographic Authority of Machine Learning Systems – DigiHistCH24 Book of Abstracts</title>
<style>code{white-space:pre-wrap}span.smallcaps{font-variant:small-caps}div.columns{gap:min(4vw,1.5em);display:flex}div.column{flex:auto;overflow-x:auto}div.hanging-indent{text-indent:-1.5em;margin-left:1.5em}ul.task-list{list-style:none}ul.task-list li input[type=checkbox]{vertical-align:middle;width:.8em;margin:0 .8em .2em -1em}.display.math{text-align:center;margin:.5rem auto;display:block}pre>code.sourceCode{white-space:pre;position:relative}pre>code.sourceCode>span{line-height:1.25}pre>code.sourceCode>span:empty{height:1.2em}.sourceCode{overflow:visible}code.sourceCode>span{color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}div.sourceCode{margin:1em 0}pre.sourceCode{margin:0}@media screen{div.sourceCode{overflow:auto}}@media print{pre>code.sourceCode{white-space:pre-wrap}pre>code.sourceCode>span{text-indent:-5em;padding-left:5em;display:inline-block}}pre.numberSource code{counter-reset:source-line 0}pre.numberSource code>span{counter-increment:source-line;position:relative;left:-4em}pre.numberSource code>span>a:first-child:before{content:counter(source-line);text-align:right;vertical-align:baseline;-webkit-touch-callout:none;-webkit-user-select:none;user-select:none;-khtml-user-select:none;border:none;width:4em;padding:0 4px;display:inline-block;position:relative;left:-1em}pre.numberSource{margin-left:3em;padding-left:4px}@media screen{pre>code.sourceCode>span>a:first-child:before{text-decoration:underline}}div.csl-entry{clear:both;margin-bottom:0}.hanging-indent div.csl-entry{text-indent:-2em;margin-left:2em}div.csl-left-margin{float:left;min-width:2em}div.csl-right-inline{margin-left:2em;padding-left:1em}div.csl-indent{margin-left:2em}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../submissions/468/index.html" rel="next">
<link href="../../submissions/464/index.html" rel="prev">
<link href="../../logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="google-site-verification" content="KXUC3maPVqC6zmAsoXiSNI45IR4zrQSF019BYYacfgQ">
<script defer="" data-domain="digihistch24.github.io/book-of-abstracts" src="https://plausible.io/js/script.outbound-links.js"></script>


<meta property="og:title" content="On the Historiographic Authority of Machine Learning Systems – DigiHistCH24 Book of Abstracts">
<meta property="og:description" content="The integration of Machine Learning in historical research has significantly altered the approach to sources, data and workflows. Historians now use Machine Learning applications such as Handwritten Text Recognition (HTR) and Natural Language Processing (NLP) to manage large corpora, enhancing research capabilities but also introducing challenges in combining machine-generated and manually created data without propagating errors. The reliability of machine-generated data is a central concern, paralleling issues found in traditional transcription and edition practices. The concept of factoids highlights the fragmentation and recontextualization of data in digital history. Evaluating Machine Learning systems, particularly through tools like CERberus for HTR, emphasises the need for qualitative error analysis to support historical research. The article proposes three strategic directions for digital history: defining clear needs to manage data pragmatically, enhancing transparency to improve data reuse and interoperability, and advancing data criticism and hermeneutics. These directions aim to refine the methods and practices of digital historians, ensuring that Machine Learning outputs are critically assessed and effectively integrated into historical scholarship.">
<meta property="og:image" content="https://digihistch24.github.io/book-of-abstracts/submissions/465/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta property="og:site_name" content="DigiHistCH24 Book of Abstracts">
<meta name="twitter:title" content="On the Historiographic Authority of Machine Learning Systems – DigiHistCH24 Book of Abstracts">
<meta name="twitter:description" content="The integration of Machine Learning in historical research has significantly altered the approach to sources, data and workflows. Historians now use Machine Learning applications such as Handwritten Text Recognition (HTR) and Natural Language Processing (NLP) to manage large corpora, enhancing research capabilities but also introducing challenges in combining machine-generated and manually created data without propagating errors. The reliability of machine-generated data is a central concern, paralleling issues found in traditional transcription and edition practices. The concept of factoids highlights the fragmentation and recontextualization of data in digital history. Evaluating Machine Learning systems, particularly through tools like CERberus for HTR, emphasises the need for qualitative error analysis to support historical research. The article proposes three strategic directions for digital history: defining clear needs to manage data pragmatically, enhancing transparency to improve data reuse and interoperability, and advancing data criticism and hermeneutics. These directions aim to refine the methods and practices of digital historians, ensuring that Machine Learning outputs are critically assessed and effectively integrated into historical scholarship.">
<meta name="twitter:image" content="https://digihistch24.github.io/book-of-abstracts/submissions/465/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="docked nav-fixed nav-sidebar">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="fixed-top headroom">
    <nav class="navbar navbar-expand-lg" data-bs-theme="dark">
      <div class="container-fluid navbar-container">
      <div class="mx-auto navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><strong><em>DigiHistCH24</em></strong> Book of Abstracts</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="window.quartoToggleHeadroom&&window.quartoToggleHeadroom();
">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="me-auto navbar-nav navbar-nav-scroll">
  <li class="nav-item">
    <a class="nav-link active" href="../../index.html" aria-current="page"> 
<span class="menu-text">Abstracts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://conferences.unibas.ch/frontend/index.php?page_id=1882" target="_blank"> 
<span class="menu-text">Conference Program</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://conferences.unibas.ch/frontend/index.php?page_id=1424&amp;booking_registration_action=show&amp;booking_registration_controller=offer" target="_blank"> 
<span class="menu-text">Registration</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://conferences.unibas.ch/frontend/index.php?folder_id=234&amp;page_id=" target="_blank"> 
<span class="menu-text">Call for Contributions</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/digihistch24/book-of-abstracts/" title="" class="px-1 quarto-navigation-tool" aria-label="" target="_blank"><i class="bi bi-github"></i></a>
  <a href="" class="px-1 quarto-navigation-tool quarto-color-scheme-toggle" onclick="return window.quartoToggleColorScheme(),!1;
" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="btn quarto-btn-toggle" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="window.quartoToggleHeadroom&&window.quartoToggleHeadroom();
">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="window.quartoToggleHeadroom&&window.quartoToggleHeadroom();
">      
          <h1 class="quarto-secondary-nav-title">On the Historiographic Authority of Machine Learning Systems</h1>
        </a>     
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="page-columns page-layout-full page-navbar page-rows-contents quarto-container">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="collapse collapse-horizontal docked overflow-auto quarto-sidebar-collapse-item sidebar sidebar-navigation">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstracts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse depth1 list-unstyled show sidebar-section">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/405/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data-Driven Approaches to Studying the History of Museums on the Web: Challenges and Opportunities for New Discoveries</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/427/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">On a solid ground. Building software for a 120-year-old research project applying modern engineering practices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/428/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tables are tricky. Testing Text Encoding Initiative (TEI) Guidelines for FAIR upcycling of digitised historical statistics.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/429/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training engineering students through a digital humanities project: Techn’hom Time Machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/431/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From manual work to artificial intelligence: developments in data literacy using the example of the Repertorium Academicum Germanicum (2001-2024)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/438/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A handful of pixels of blood</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/443/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Impresso 2: Connecting Historical Digitised Newspapers and Radio. A Challenge at the Crossroads of History, User Interfaces and Natural Language Processing.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/444/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Learning to Read Digital? Constellations of Correspondence Project and Humanist Perspectives on the Aggregated 19th-century Finnish Letter Metadata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/445/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Teaching the use of Automated Text Recognition online. Ad fontes goes ATR</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/447/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geovistory, a LOD Research Infrastructure for Historical Sciences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/450/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Using GIS to Analyze the Development of Public Urban Green Spaces in Hamburg and Marseille (1945 - 1973)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/452/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Belpop, a history-computer project to study the population of a town during early industrialization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/453/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing to a Paradigm Shift in Historical Research by Teaching Digital Methods to Master’s Students</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/454/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Revealing the Structure of Land Ownership through the Automatic Vectorisation of Swiss Cadastral Plans</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/455/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rockefeller fellows as heralds of globalization: the circulation of elites, knowledge, and practices of modernization (1920–1970s): global history, database connection, and teaching experience</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/456/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Theory and Practice of Historical Data Versioning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/457/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Towards Computational Historiographical Modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/458/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Efficacy of Chat GPT Correlations vs.&nbsp;Co-occurrence Networks in Deciphering Chinese History</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/459/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Literacy and the Role of Libraries</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/460/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">20 godparents and 3 wives – studying migrant glassworkers in post-medieval Estonia</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/462/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From record cards to the dynamics of real estate transactions: Working with automatically extracted information from Basel’s historical land register, 1400-1700</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/464/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">When the Data Becomes Meta: Quality Control for Digitized Ancient Heritage Collections</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/465/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">On the Historiographic Authority of Machine Learning Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/468/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Films as sources and as means of communication for knowledge gained from historical research</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/469/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Develop Yourself! Development according to the Rockefeller Foundation (1913 – 2013)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/471/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI-assisted Search for Digitized Publication Archives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/473/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Digital Film Collection Literacy – Critical Research Interfaces for the “Encyclopaedia Cinematographica”</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/474/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Source-Criticism to System-Criticism, Born Digital Objects, Forensic Methods, and Digital Literacy for All</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/480/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Connecting floras and herbaria before 1850 – challenges and lessons learned in digital history of biodiversity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/482/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A Digital History of Internationalization. Operationalizing Concepts and Exploring Millions of Patent Documents</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/486/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From words to numbers. Methodological perspectives on large scale Named Entity Linking</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/687/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Go Digital, They Said. It Will Be Fun, They Said. Teaching DH Methods for Historical Research</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../submissions/keynote/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">When Literacy Goes Digital: Rethinking the Ethics and Politics of Digitisation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse depth1 list-unstyled show sidebar-section">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../CHANGELOG.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Changelog</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../CODE_OF_CONDUCT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Code of Conduct</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../CONTRIBUTING.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../LICENSE-CCBYSA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">License (Data)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../LICENSE-AGPL.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">License (Code)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../SECURITY.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Security</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="margin-sidebar sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#facticity" id="toc-facticity" class="nav-link" data-scroll-target="#facticity">Facticity</a></li>
  <li><a href="#qualifying-error-rates" id="toc-qualifying-error-rates" class="nav-link" data-scroll-target="#qualifying-error-rates">Qualifying Error Rates</a></li>
  <li><a href="#three-strategic-directions" id="toc-three-strategic-directions" class="nav-link" data-scroll-target="#three-strategic-directions">Three Strategic Directions</a>
  <ul class="collapse">
  <li><a href="#direction-1-formulating-clear-needs" id="toc-direction-1-formulating-clear-needs" class="nav-link" data-scroll-target="#direction-1-formulating-clear-needs">Direction 1: Formulating Clear Needs</a></li>
  <li><a href="#direction-2-creating-transparency" id="toc-direction-2-creating-transparency" class="nav-link" data-scroll-target="#direction-2-creating-transparency">Direction 2: Creating Transparency</a></li>
  <li><a href="#direction-3-data-criticism-and-data-hermeneutics" id="toc-direction-3-data-criticism-and-data-hermeneutics" class="nav-link" data-scroll-target="#direction-3-data-criticism-and-data-hermeneutics">Direction 3: Data Criticism and Data Hermeneutics</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/digihistch24/book-of-abstracts/edit/main/submissions/465/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/digihistch24/book-of-abstracts/issues/new/choose" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="column-body content" id="quarto-document-content">

<header id="title-block-header" class="default quarto-title-block">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="d-lg-block d-none title">On the Historiographic Authority of Machine Learning Systems</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Session 4B</div>
  </div>
  </div>


<div class="column-body quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Dominic Weber <a href="mailto:dominic.weber@unibe.ch" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0002-9265-3388" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==" alt=""></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Bern
          </p>
        <p class="affiliation">
            University of Basel
          </p>
      </div>
  </div>

<div class="column-body quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 23, 2024</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>The integration of Machine Learning in historical research has significantly altered the approach to sources, data and workflows. Historians now use Machine Learning applications such as Handwritten Text Recognition (HTR) and Natural Language Processing (NLP) to manage large corpora, enhancing research capabilities but also introducing challenges in combining machine-generated and manually created data without propagating errors. The reliability of machine-generated data is a central concern, paralleling issues found in traditional transcription and edition practices. The concept of factoids highlights the fragmentation and recontextualization of data in digital history. Evaluating Machine Learning systems, particularly through tools like CERberus for HTR, emphasises the need for qualitative error analysis to support historical research. The article proposes three strategic directions for digital history: defining clear needs to manage data pragmatically, enhancing transparency to improve data reuse and interoperability, and advancing data criticism and hermeneutics. These directions aim to refine the methods and practices of digital historians, ensuring that Machine Learning outputs are critically assessed and effectively integrated into historical scholarship.</p>
  </div>
</div>

<div>
  <div class="keywords">
    <div class="block-title">Keywords</div>
    <p>Machine Learning, Methodology, Epistemology, Facticity, Evaluation</p>
  </div>
</div>

</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Over the last few years, Machine Learning applications became more and more popular in the humanities and social sciences in general, and therefore also in history. Handwritten Text Recognition (HTR) and various tasks of Natural Language Processing (NLP) are now commonly employed in a plethora of research projects of various sizes. Even for PhD projects it is now feasible to research large corpora like serial legal source, which would not be possible entirely by hand. This acceleration of research processes implies fundamental changes to how we think about sources, data, research and workflows.</p>
<p>In history, Machine Learning systems are typically used to speed up the production of research data. As the output of these applications is never entirely accurate or correct, this raises the question how historians can use machine generated data together with manually created data without propagating errors and uncertainties to downstream tasks and investigations.</p>
</section>
<section id="facticity" class="level2">
<h2 class="anchored" data-anchor-id="facticity">Facticity</h2>
<p>The question of the combined usability of machine-generated and manually generated data is also a question of the reliability or facticity of data. Data generated by humans are not necessarily complete and correct either, as they are a product of human perception. For example, creating transcriptions depends on the respective transcription guidelines and individual text understanding, which can lead to errors. However, we consider transcriptions by experts as correct and use them for historical research. This issue is even more evident in the field of editions. Even very old editions with methodological challenges are valued for their core content. Errors may exist, but they are largely accepted due to the expertise of the editors, treating the output as authorised. This pragmatic approach enables efficient historical research. Historians trust their ability to detect and correct errors during research.</p>
<p>Francesco Beretta represents data, information, and knowledge as a pyramid: data form the base, historical information (created from data through conceptual models and critical methods) forms the middle, and historical knowledge (produced from historical information through theories, statistical models and heuristics) forms the top <span class="citation" data-cites="berettaDonneesOuvertesLiees2023">(<a href="#ref-berettaDonneesOuvertesLiees2023" role="doc-biblioref">Beretta 2023, fig. 3</a>)</span>. Interestingly, however, he makes an important distinction regarding digital data: “Digital data does not belong to the epistemic layer of data, but to the layer of information, of which they are the information technical carrier” <span class="citation" data-cites="berettaDonneesOuvertesLiees2023">(Translation: DW. Original Text: “[L]les données numériques n’appartiennent pas à la strate épistémique des données, mais bien à celle de l’information dont elles constituent le support informatique.” <a href="#ref-berettaDonneesOuvertesLiees2023" role="doc-biblioref">Beretta 2023, 18</a>)</span></p>
<p>Andreas Fickers adds that digitization transforms the nature of sources, affecting the concept of the original <span class="citation" data-cites="fickersUpdateFuerHermeneutik2020">(<a href="#ref-fickersUpdateFuerHermeneutik2020" role="doc-biblioref">Fickers 2020, 162</a>)</span>. Sources are preprocessed using HTR/OCR and various NLP strategies. The resulting digital data are already processed historical information. This shift from analog to digital means that what we extract from sources is not just given but constructed <span class="citation" data-cites="berettaDonneesOuvertesLiees2023">(<a href="#ref-berettaDonneesOuvertesLiees2023" role="doc-biblioref">Beretta 2023, 26</a>)</span>. Analog historical research, which relies on handwritten archival documents, also depends on transcriptions or editions to conduct research pragmatically; and here, too, data becomes information. The main difference is that with the generation of digital data, the (often linear) structure of sources is typically dissolved in favour of a highly fragmented and hyperconnected structure <span class="citation" data-cites="fickersWhatDoesHistory2022 landowHypertextCriticalTheory2006 weberKlassifizierenVerknupfenAbbilden2021">(For hyperconnectivity see <a href="#ref-fickersWhatDoesHistory2022" role="doc-biblioref">Fickers 2022, 51–54</a>; For the underlying concept of hypertextual systems see <a href="#ref-landowHypertextCriticalTheory2006" role="doc-biblioref">Landow 2006, 53–58</a>; for a a more extensive discussion of digital representations of fragmented texts see <a href="#ref-weberKlassifizierenVerknupfenAbbilden2021" role="doc-biblioref">Weber 2021</a>)</span>. This is partly due to the way sources are processed into historical information using digital tools and methods, but it is inherently connected with issues of storing, retrieving, and presenting digital data – in a very technical sense.</p>
<p>The concept of <em>factoids</em> introduced by Michele Pasin and John Bradley, is central to this argument. They define factoids as pieces of information about one or more persons in a primary source. Those factoids are then represented in a semantic network of subject-predicate-object triples <span class="citation" data-cites="pasinFactoidbasedProsopographyComputer2015">(<a href="#ref-pasinFactoidbasedProsopographyComputer2015" role="doc-biblioref">Pasin and Bradley 2015, 89–90</a>)</span>. This involves extracting statements from their original context, placing them in a new context, and outsourcing verification to later steps. Therefore, factoids can be contradictory. Francesco Beretta applies this idea to historical science, viewing the aggregation of factoids as a process aiming for the best possible approximation of facticity <span class="citation" data-cites="berettaDonneesOuvertesLiees2023">(<a href="#ref-berettaDonneesOuvertesLiees2023" role="doc-biblioref">Beretta 2023, 20</a>)</span>. The challenge is to verify machine output sufficiently for historical research and to assess the usefulness of the factoid concept. Evaluating machine learning models and their outputs is crucial for this.</p>
</section>
<section id="qualifying-error-rates" class="level2">
<h2 class="anchored" data-anchor-id="qualifying-error-rates">Qualifying Error Rates</h2>
<p>Evaluating the output of a machine learning system is not trivial. Models can be evaluated using various calculated scores, which is done continuously during the training process. However, these performance metrics are statistical measures that generally refer to the model and are based on a set of test data. Even the probabilities output by machine learning systems when applied to new data are purely computational figures, only partially suitable for quality assurance. This verification is further complicated by the potentially vast scale of the output. Therefore, historical science must find a pragmatic way to translate statistical evaluation metrics into qualitative statements and identify systematic sources of error.</p>
<p>In automatic handwriting recognition, models are typically evaluated using character error rate (CER). These metrics only tell us the percentage of characters or words incorrectly recognised compared to a ground truth. They do not reveal the distribution of these errors, which is important when comparing automatic and manual transcriptions. For detailed HTR model evaluation, CERberus is being developed <span class="citation" data-cites="haverals2023cerberus">(<a href="#ref-haverals2023cerberus" role="doc-biblioref">Haverals 2023</a>)</span>. This tool compares ground truth with HTR output from the same source. Instead of calculating just the character error rate, it breaks down the differences further. Errors are categorised into missing, excess, and incorrectly recognised characters. Additionally, a separate CER is calculated for all characters and Unicode blocks in the text, aggregated into confusion statistics that identify the most frequently confused characters. Confusion plots are generated to show the most common errors for each character. These metrics do not pinpoint specific errors but provide a more precise analysis of the model’s behaviour. CERberus cannot evaluate entirely new HTR output without comparison text but is a valuable tool for Digital History, revealing which character forms are often confused and guiding model improvement or post-processing strategies.</p>
<p>In other machine learning applications, such as named entity recognition (NER), different metrics are important, requiring detailed error source analysis. Evaluating NER is more complex than HTR because it involves categorizing longer text sections based on context. Precision (how many recognised positives are true positives) and recall (how many actual positives are recognised) are combined into the F1-score to indicate model performance. Fu et al.&nbsp;proposed evaluating NER with a set of eight annotation attributes influencing model performance. These attributes are divided into local properties (entity length, sentence length, unknown word density, entity density) and aggregated attributes (annotation consistency and frequency at the token and entity levels) <span class="citation" data-cites="fuInterpretableMultidatasetEvaluation2020">(<a href="#ref-fuInterpretableMultidatasetEvaluation2020" role="doc-biblioref">Fu, Liu, and Neubig 2020, 3</a>)</span>. Buckets of source points where a model performs particularly well or poorly are created and separately evaluated <span class="citation" data-cites="fuInterpretableMultidatasetEvaluation2020">(<a href="#ref-fuInterpretableMultidatasetEvaluation2020" role="doc-biblioref">Fu, Liu, and Neubig 2020, 1</a>)</span>. This analysis identifies conditions affecting model performance, guiding further training steps and dataset expansion.</p>
<p>The qualitative error analysis presented here does not solve the question of authorizing machine learning output for historical research. Instead, it provides tools to assess models more precisely and analyse training and test datasets. Such investigations extend the crucial source criticism in historical science to digital datasets and the algorithms and models involved in their creation. This requires historians to expand their traditional methods to include new, less familiar areas.</p>
</section>
<section id="three-strategic-directions" class="level2">
<h2 class="anchored" data-anchor-id="three-strategic-directions">Three Strategic Directions</h2>
<p>In the following last part of this article, the previously raised questions and problem areas will be consolidated, from which three strategic directions for digital history will be derived. These will be suggestions for how the theory, methodology, and practice of Digital History could evolve to address and mitigate the identified problem areas. The three perspectives should not be viewed in isolation or as mutually exclusive. Instead, they are interdependent and should work together to meet the additional challenges.</p>
<section id="direction-1-formulating-clear-needs" class="level3">
<h3 class="anchored" data-anchor-id="direction-1-formulating-clear-needs">Direction 1: Formulating Clear Needs</h3>
<p>When data is collected or processed into information in the historical research process a certain pragmatism is involved. Ideally, such a project would fully and consistently transcribe the entire collection with the same thoroughness, but in practice, a compromise is often found between completeness, correctness, and pragmatism. Often, for one’s own research purposes, it is sufficient to transcribe a source only to the extent that its meaning can be understood. This compromise has not fully transitioned into Digital History. Even if a good CER is achieved, there is pressure to justify how these potential errors are managed in the subsequent research process. This skepticism is not fundamentally bad, and the epistemological consequences of erroneous machine learning output are worthy of discussion. Nonetheless, the resulting text is usually quite readable and usable.</p>
<p>Thus, I argue that digital history must more clearly define and communicate its needs. However, it must be remembered that Digital History also faces broader demands. Especially in machine learning-supported research, the demand for data interoperability is rightly emphasised. Incomplete or erroneous datasets are, of course, less reusable by other research projects.</p>
</section>
<section id="direction-2-creating-transparency" class="level3">
<h3 class="anchored" data-anchor-id="direction-2-creating-transparency">Direction 2: Creating Transparency</h3>
<p>The second direction for digital history is to move towards greater transparency. The issue of reusability and interoperability of datasets from the first strategic direction can be at least partially mitigated by transparency.</p>
<p>As Hodel et al.&nbsp;convincingly argued, it is extremely sensible and desirable for projects using HTR to publish their training data. This allows for gradual development towards models that can generalise as broadly as possible <span class="citation" data-cites="hodelGeneralModelsHandwritten2021">(<a href="#ref-hodelGeneralModelsHandwritten2021" role="doc-biblioref">Hodel et al. 2021, 7–8</a>)</span>. If a CERberus error analysis is conducted for HTR that goes beyond the mere CER, it makes sense to publish this alongside the data and the model. With this information, it is easier to assess whether it might be worthwhile to include this dataset in one’s own training material. Similarly, when NER models are published, an extended evaluation according to Fu et al.&nbsp;helps to better assess the performance of a model for one’s own dataset.</p>
<p>Pasin and Bradley, in their prosopographic graph database, indicate the provenance of each data point and who captured it <span class="citation" data-cites="pasinFactoidbasedProsopographyComputer2015">(<a href="#ref-pasinFactoidbasedProsopographyComputer2015" role="doc-biblioref">Pasin and Bradley 2015, 91–92</a>)</span>. This principle could also be interesting for Digital History, by indicating in the metadata whether published research data was generated manually or by a machine, ideally with information about the model used and the annotating person for manually generated data. Models provide a confidence estimate with their prediction, indicating how likely the prediction is correct. The most probable prediction would be treated as the first factoid. The second or even third most probable prediction from the systems cloud provide additional factoids that can be incorporate into the source representation. These additional pieces of information can support the further research process by allowing inconsistencies and errors to be better assessed and balanced.</p>
</section>
<section id="direction-3-data-criticism-and-data-hermeneutics" class="level3">
<h3 class="anchored" data-anchor-id="direction-3-data-criticism-and-data-hermeneutics">Direction 3: Data Criticism and Data Hermeneutics</h3>
<p>The shift to digital history requires an evaluation and adjustment of our hermeneutic methods. This ongoing discourse is not new, and Torsten Hiltmann has identified three broad directions: first, the debate about extending source criticism to data, algorithms, and interfaces; second, the call for computer-assisted methods to support text understanding; and third, the theorization of data hermeneutics, or the “understanding of and with data” <span class="citation" data-cites="hiltmann2024">(<a href="#ref-hiltmann2024" role="doc-biblioref">Hiltmann 2024, 208</a>)</span>.</p>
<p>Even though these discourse strands cannot be sharply separated, the focus here is primarily on data criticism and hermeneutics. The former can fundamentally orient itself towards classical source criticism. Since digital data is not given but constructed, it is crucial to discuss by whom, for what purpose, and how data was generated. This is no easy task, especially when datasets are poorly documented. Therefore, the call for data and model criticism is closely linked to the plea for more transparency in data and model publication.</p>
<p>In the move towards data hermeneutics, a thorough rethinking of the factoid principle can be fruitful. If, as suggested above, the second or even third most likely predictions of a model are included as factoids in the publication of research data, this opens up additional perspectives on the sources underlying the data. From these new standpoints, the data – and thus the sources – can be analyzed and understood more thoroughly. Additionally, this allows for a more informed critique of the data, and extensive transparency also mitigates the “black box” problem of interpretation described by Silke Schwandt <span class="citation" data-cites="schwandtOpeningBlackBox2022">(<a href="#ref-schwandtOpeningBlackBox2022" role="doc-biblioref">Schwandt 2022</a>)</span>. If we more precisely describe and reflect on how we generate digital data from sources as historians, we will find that our methods are algorithmic <span class="citation" data-cites="schwandtOpeningBlackBox2022">(<a href="#ref-schwandtOpeningBlackBox2022" role="doc-biblioref">Schwandt 2022, 81–82</a>)</span>. This insight can also support the understanding of how machine learning applications work. Data hermeneutics thus requires both a critical reflection of our methods and a more transparent approach to data and metadata.</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="csl-bib-body hanging-indent references" data-entry-spacing="0" role="list">
<div id="ref-berettaDonneesOuvertesLiees2023" class="csl-entry" role="listitem">
Beretta, Francesco. 2023. <span>“<span>Donn<span>é</span>es ouvertes li<span>é</span>es et recherche historique : un changement de paradigme</span>.”</span> <em>Humanit<span>é</span>s num<span>é</span>riques</em>, no. 7 (July). <a href="https://doi.org/10.4000/revuehn.3349">https://doi.org/10.4000/revuehn.3349</a>.
</div>
<div id="ref-fickersUpdateFuerHermeneutik2020" class="csl-entry" role="listitem">
Fickers, Andreas. 2020. <span>“<span>Update f<span>ü</span>r die Hermeneutik. Geschichtswissenschaft auf dem Weg zur digitalen Forensik?</span>”</span> <em>Zeithistorische Forschungen</em> 1: 157–68. <a href="https://doi.org/10.14765/ZZF.DOK-1765">https://doi.org/10.14765/ZZF.DOK-1765</a>.
</div>
<div id="ref-fickersWhatDoesHistory2022" class="csl-entry" role="listitem">
———. 2022. <span>“<span>What the D does to history: Das digitale Zeitalter als neues historisches Zeitregime?</span>”</span> In <em><span>Digital History: Konzepte, Methoden und Kritiken Digitaler Geschichtswissenschaft</span></em>, edited by Karoline Dominika Döring, Stefan Haas, Mareike König, and Jörg Wettlaufer, 45–64. De Gruyter Oldenbourg. <a href="https://doi.org/10.1515/9783110757101-003">https://doi.org/10.1515/9783110757101-003</a>.
</div>
<div id="ref-fuInterpretableMultidatasetEvaluation2020" class="csl-entry" role="listitem">
Fu, Jinlan, Pengfei Liu, and Graham Neubig. 2020. <span>“Interpretable <span class="nocase">Multi-dataset Evaluation</span> for <span>Named Entity Recognition</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2011.06854">https://doi.org/10.48550/arXiv.2011.06854</a>.
</div>
<div id="ref-haverals2023cerberus" class="csl-entry" role="listitem">
Haverals, Wouter. 2023. <span>“<span>CERberus</span>: Guardian Against Character Errors.”</span> <a href="https://github.com/WHaverals/CERberus">https://github.com/WHaverals/CERberus</a>.
</div>
<div id="ref-hiltmann2024" class="csl-entry" role="listitem">
Hiltmann, Torsten. 2024. <span>“<span>Hermeneutik in Zeiten der KI: Large Language Models als hermeneutische Instrumente in den Geschichtswissenschaften</span>.”</span> In <em><span>KI:Text</span></em>, 201–32. De Gruyter. <a href="https://doi.org/10.1515/9783111351490-014">https://doi.org/10.1515/9783111351490-014</a>.
</div>
<div id="ref-hodelGeneralModelsHandwritten2021" class="csl-entry" role="listitem">
Hodel, Tobias, David Schoch, Christa Schneider, and Jake Purcell. 2021. <span>“General <span>Models</span> for <span>Handwritten Text Recognition</span>: <span>Feasibility</span> and <span class="nocase">State-of-the Art</span>. <span>German Kurrent</span> as an <span>Example</span>.”</span> <em>Journal of Open Humanities Data</em> 7. <a href="https://doi.org/10.5334/johd.46">https://doi.org/10.5334/johd.46</a>.
</div>
<div id="ref-landowHypertextCriticalTheory2006" class="csl-entry" role="listitem">
Landow, George P. 2006. <em>Hypertext 3.0: <span>Critical Theory</span> and <span>New Media</span> in an <span>Era</span> of <span>Globalization</span></em>. 3. Auflage. Baltimore.
</div>
<div id="ref-pasinFactoidbasedProsopographyComputer2015" class="csl-entry" role="listitem">
Pasin, Michele, and John Bradley. 2015. <span>“Factoid-Based Prosopography and Computer Ontologies: Towards an Integrated Approach.”</span> <em>Digital Scholarship in the Humanities</em> 30 (1): 86–97. <a href="https://doi.org/10.1093/llc/fqt037">https://doi.org/10.1093/llc/fqt037</a>.
</div>
<div id="ref-schwandtOpeningBlackBox2022" class="csl-entry" role="listitem">
Schwandt, Silke. 2022. <span>“Opening the <span>Black Box</span> of <span>Interpretation</span>: <span>Digital History Practices</span> as <span>Models</span> of <span>Knowledge</span>.”</span> <em>History and Theory</em> 61 (4): 77–85. <a href="https://doi.org/10.1111/hith.12281">https://doi.org/10.1111/hith.12281</a>.
</div>
<div id="ref-weberKlassifizierenVerknupfenAbbilden2021" class="csl-entry" role="listitem">
Weber, Dominic. 2021. <span>“Klassifizieren – <span class="nocase">Verkn<span class="nocase">ü</span>pfen</span> – <span>Abbilden</span>. <span>Herausforderungen</span> Der Digitalen <span class="nocase">Repr<span class="nocase">ä</span>sentation</span> Hypertextueller <span>Systeme</span> Am <span>Beispiel</span> Des <span>Klingentaler Jahrzeitenbuchs H</span>.”</span> Master’s thesis, Basel: University of Basel. <a href="https://github.com/DominicWeber/jahrzeitenbuch-h">https://github.com/DominicWeber/jahrzeitenbuch-h</a>.
</div>
</div>


<!-- -->

</section>

<a onclick="return window.scrollTo(0,0),!1;
" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@misc{weber2024,
  author = {Weber, Dominic},
  editor = {Baudry, Jérôme and Burkart, Lucas and Joyeux-Prunel,
    Béatrice and Kurmann, Eliane and Mähr, Moritz and Natale, Enrico and
    Sibille, Christiane and Twente, Moritz},
  title = {On the {Historiographic} {Authority} of {Machine} {Learning}
    {Systems}},
  date = {2024-07-23},
  url = {https://digihistch24.github.io/book-of-abstracts/submissions/465/},
  langid = {en},
  abstract = {The integration of Machine Learning in historical research
    has significantly altered the approach to sources, data and
    workflows. Historians now use Machine Learning applications such as
    Handwritten Text Recognition (HTR) and Natural Language Processing
    (NLP) to manage large corpora, enhancing research capabilities but
    also introducing challenges in combining machine-generated and
    manually created data without propagating errors. The reliability of
    machine-generated data is a central concern, paralleling issues
    found in traditional transcription and edition practices. The
    concept of factoids highlights the fragmentation and
    recontextualization of data in digital history. Evaluating Machine
    Learning systems, particularly through tools like CERberus for HTR,
    emphasises the need for qualitative error analysis to support
    historical research. The article proposes three strategic directions
    for digital history: defining clear needs to manage data
    pragmatically, enhancing transparency to improve data reuse and
    interoperability, and advancing data criticism and hermeneutics.
    These directions aim to refine the methods and practices of digital
    historians, ensuring that Machine Learning outputs are critically
    assessed and effectively integrated into historical scholarship.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-weber2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Weber, Dominic. 2024. <span>“On the Historiographic Authority of Machine
Learning Systems.”</span> Edited by Jérôme Baudry, Lucas Burkart,
Béatrice Joyeux-Prunel, Eliane Kurmann, Moritz Mähr, Enrico Natale,
Christiane Sibille, and Moritz Twente. <em>Digital History Switzerland
2024: Book of Abstracts</em>. <a href="https://digihistch24.github.io/book-of-abstracts/submissions/465/">https://digihistch24.github.io/book-of-abstracts/submissions/465/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">window.document.addEventListener("DOMContentLoaded",function($){const q=e=>{const t=e.getAttribute("data-mode"),o=window.document.querySelector("body");t==="dark"?(o.classList.add("quarto-dark"),o.classList.remove("quarto-light")):(o.classList.add("quarto-light"),o.classList.remove("quarto-dark"))},E=()=>{const e=window.document.querySelector("link#quarto-bootstrap");e&&q(e)};E();const U=e=>{for(let t=0;t<e.length;t++){const o=e[t];o.rel="prefetch"}},W=e=>{for(let t=0;t<e.length;t++){const o=e[t];o.rel="stylesheet"}},g=(e,t)=>{const o=window.document.querySelectorAll(e);for(let n=0;n<o.length;n++){const l=o[n];t?l.classList.remove("notransition"):l.classList.add("notransition")}},G=(e,t)=>{const o=document.querySelector("#giscus-base-theme")?.value??"light",n=document.querySelector("#giscus-alt-theme")?.value??"dark";let l="";t?l=e?o:n:l=e?n:o;const i=()=>{(a=>{const u=document.querySelector("iframe.giscus-frame");u&&u.contentWindow.postMessage({giscus:a},"https://giscus.app")})({setConfig:{theme:l}})};window.document.querySelector("iframe.giscus-frame")!==null&&i()},w=e=>{const t=window.document.querySelectorAll("link.quarto-color-scheme.quarto-color-alternate");if(g("#quarto-margin-sidebar .nav-link",!1),e){W(t);for(const n of t)n.id==="quarto-bootstrap"&&q(n)}else U(t),E();g("#quarto-margin-sidebar .nav-link",!0);const o=window.document.querySelectorAll(".quarto-color-scheme-toggle");for(let n=0;n<o.length;n++){const l=o[n];l&&(e?l.classList.add("alternate"):l.classList.remove("alternate"))}navigator.userAgent.indexOf("Safari")>0&&navigator.userAgent.indexOf("Chrome")==-1&&(g("body",!1),window.scrollTo(0,1),setTimeout(()=>{window.scrollTo(0,0),g("body",!0)},40))},S=()=>window.location.protocol==="file:",L=()=>{let e=P();return e!==null?e==="alternate":!1},J=e=>{const t=e?"alternate":"default";S()?p=t:window.localStorage.setItem("quarto-color-scheme",t)},P=()=>{if(S())return p;{const e=window.localStorage.getItem("quarto-color-scheme");return e??p}},A=!1;let p=A?"alternate":"default";if(window.quartoToggleColorScheme=()=>{let e=!L();w(e),J(e),G(e,A)},window.document.querySelector(".quarto-color-scheme-toggle")===null){const e=window.document.createElement("a");e.classList.add("top-right"),e.classList.add("quarto-color-scheme-toggle"),e.href="",e.onclick=function(){try{window.quartoToggleColorScheme()}catch{}return!1};const t=window.document.createElement("i");t.classList.add("bi"),e.appendChild(t),window.document.body.appendChild(e)}L()?w(!0):w(!1);const z="\uE9CB",C=new window.AnchorJS;C.options={placement:"right",icon:z},C.add(".anchored");const j=e=>{for(const t of e.classList)if(t.startsWith("code-annotation-"))return!0;return!1},T=function(e){const t=e.trigger;t.blur(),t.classList.add("code-copy-button-checked");var o=t.getAttribute("title");t.setAttribute("title","Copied!");let n;window.bootstrap&&(t.setAttribute("data-bs-toggle","tooltip"),t.setAttribute("data-bs-placement","left"),t.setAttribute("data-bs-title","Copied!"),n=new bootstrap.Tooltip(t,{trigger:"manual",customClass:"code-copy-button-tooltip",offset:[0,-8]}),n.show()),setTimeout(function(){n&&(n.hide(),t.removeAttribute("data-bs-title"),t.removeAttribute("data-bs-toggle"),t.removeAttribute("data-bs-placement")),t.setAttribute("title",o),t.classList.remove("code-copy-button-checked")},1e3),e.clearSelection()},k=function(e){const t=e.previousElementSibling.cloneNode(!0);for(const o of t.children)j(o)&&o.remove();return t.innerText};new window.ClipboardJS(".code-copy-button:not([data-in-quarto-modal])",{text:k}).on("success",T),window.document.getElementById("quarto-embedded-source-code-modal")&&new window.ClipboardJS(".code-copy-button[data-in-quarto-modal]",{text:k,container:window.document.getElementById("quarto-embedded-source-code-modal")}).on("success",T);const b=window.document.getElementById("quarto-view-source")||window.document.getElementById("quarto-code-tools-source");if(b){const e=b.getAttribute("data-quarto-source-url");b.addEventListener("click",function(t){return e?/\bcapabilities=\b/.test(window.location)?window.open(e):window.location.href=e:new bootstrap.Modal(document.getElementById("quarto-embedded-source-code-modal")).show(),!1})}function x(e){return function(t){const o=window.document.querySelectorAll(".cell > details > .sourceCode");for(let r=0;r<o.length;r++){const s=o[r].parentElement;e?s.open=!0:s.removeAttribute("open")}const n=window.document.querySelectorAll(".cell > .sourceCode"),l=e?"hidden":"unhidden",i=e?"unhidden":"hidden";for(let r=0;r<n.length;r++){const s=n[r];s.classList.contains(l)&&(s.classList.remove(l),s.classList.add(i))}return!1}}const M=window.document.getElementById("quarto-hide-all-code");M&&M.addEventListener("click",x(!1));const I=window.document.getElementById("quarto-show-all-code");I&&I.addEventListener("click",x(!0));for(var F=new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//),V=new RegExp(/^mailto:/),X=new RegExp("https://digihistch24.github.io/book-of-abstracts/"),_=e=>X.test(e)||F.test(e)||V.test(e),B=window.document.querySelectorAll("a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)"),c=0;c<B.length;c++){const e=B[c];_(e.href)||(e.dataset.originalHref!==void 0&&(e.href=e.dataset.originalHref),e.setAttribute("target","_blank"),e.getAttribute("rel")===null&&e.setAttribute("rel","noopener"),e.classList.add("external"))}function y(e,t,o,n){const l={allowHTML:!0,maxWidth:500,delay:100,arrow:!1,appendTo:function(i){return i.parentElement},interactive:!0,interactiveBorder:10,theme:"quarto",placement:"bottom-start"};t&&(l.content=t),o&&(l.onTrigger=o),n&&(l.onUntrigger=n),window.tippy(e,l)}const D=window.document.querySelectorAll('a[role="doc-noteref"]');for(var c=0;c<D.length;c++){const t=D[c];y(t,function(){let o=t.getAttribute("data-footnote-href")||t.getAttribute("href");try{o=new URL(o).hash}catch{}const n=o.replace(/^#\/?/,""),l=window.document.getElementById(n);return l?l.innerHTML:""})}const H=window.document.querySelectorAll("a.quarto-xref"),v=(e,t)=>{const o=n=>{if(n.classList.remove("page-full","page-columns"),n.children)for(const l of n.children)o(l)};if(o(t),e===null||e.startsWith("sec-")){const n=document.createElement("div");if(t.children&&t.children.length>2){n.appendChild(t.children[0].cloneNode(!0));for(let l=1;l<t.children.length;l++){const i=t.children[l];if(!(i.tagName==="P"&&i.innerText==="")){n.appendChild(i.cloneNode(!0));break}}return window.Quarto?.typesetMath&&window.Quarto.typesetMath(n),n.innerHTML}else return window.Quarto?.typesetMath&&window.Quarto.typesetMath(t),t.innerHTML}else{const n=t.querySelector("a.anchorjs-link");return n&&n.remove(),window.Quarto?.typesetMath&&window.Quarto.typesetMath(t),t.classList.contains("callout")?t.outerHTML:t.innerHTML}};for(var c=0;c<H.length;c++){const t=H[c];y(t,void 0,function(o){o.disable();let n=t.getAttribute("href"),l;if(n.startsWith("#"))l=n;else try{l=new URL(n).hash}catch{}if(l){const i=l.replace(/^#\/?/,""),r=window.document.getElementById(i);if(r!==null)try{const s=v(i,r.cloneNode(!0));o.setContent(s)}finally{o.enable(),o.show()}else fetch(n.split("#")[0]).then(s=>s.text()).then(s=>{const f=new DOMParser().parseFromString(s,"text/html").getElementById(i);if(f!==null){const d=v(i,f);o.setContent(d)}}).finally(()=>{o.enable(),o.show()})}else fetch(n).then(i=>i.text()).then(i=>{const a=new DOMParser().parseFromString(i,"text/html").querySelector("main.content");if(a!==null){a.children.length>0&&a.children[0].tagName==="HEADER"&&a.children[0].remove();const u=v(null,a);o.setContent(u)}}).finally(()=>{o.enable(),o.show()})},function(o){})}let h;const K=(e,t)=>{let o='data-code-cell="'+e+'"',n='data-code-annotation="'+t+'"';return"span["+o+"]["+n+"]"},R=e=>{const t=window.document,o=e.getAttribute("data-target-cell"),n=e.getAttribute("data-target-annotation"),r=window.document.querySelector(K(o,n)).getAttribute("data-code-lines").split(",").map(f=>o+"-"+f);let s=null,a=null,u=null;if(r.length>0){const f=window.document.getElementById(r[0]);if(s=f.offsetTop,a=f.offsetHeight,u=f.parentElement.parentElement,r.length>1){const d=window.document.getElementById(r[r.length-1]);a=d.offsetTop+d.offsetHeight-s}if(s!==null&&a!==null&&u!==null){let d=window.document.getElementById("code-annotation-line-highlight");d===null&&(d=window.document.createElement("div"),d.setAttribute("id","code-annotation-line-highlight"),d.style.position="absolute",u.appendChild(d)),d.style.top=s-2+"px",d.style.height=a+4+"px",d.style.left=0;let m=window.document.getElementById("code-annotation-line-highlight-gutter");m===null&&(m=window.document.createElement("div"),m.setAttribute("id","code-annotation-line-highlight-gutter"),m.style.position="absolute",window.document.getElementById(o).querySelector(".code-annotation-gutter").appendChild(m)),m.style.top=s-2+"px",m.style.height=a+4+"px"}h=e}},N=()=>{["code-annotation-line-highlight","code-annotation-line-highlight-gutter"].forEach(t=>{const o=window.document.getElementById(t);o&&o.remove()}),h=void 0};window.addEventListener("resize",Y(()=>{elRect=void 0,h&&R(h)},10));function Y(e,t){let o=!1,n;return(...l)=>{o?(n&&clearTimeout(n),n=setTimeout(()=>{e.apply(this,l),n=o=!1},t)):(e.apply(this,l),o=!0)}}const Z=window.document.querySelectorAll("dt[data-target-cell]");for(const e of Z)e.addEventListener("click",t=>{const o=t.target;if(o!==h){N();const n=window.document.querySelector("dt[data-target-cell].code-annotation-active");n&&n.classList.remove("code-annotation-active"),R(o),o.classList.add("code-annotation-active")}else N(),o.classList.remove("code-annotation-active")});const Q=e=>{const t=e.parentElement;if(t){const o=t.dataset.cites;return o?{el:e,cites:o.split(" ")}:Q(e.parentElement)}else return};for(var O=window.document.querySelectorAll('a[role="doc-biblioref"]'),c=0;c<O.length;c++){const t=O[c],o=Q(t);o&&y(o.el,function(){var n=window.document.createElement("div");return o.cites.forEach(function(l){var i=window.document.createElement("div");i.classList.add("hanging-indent"),i.classList.add("csl-entry");var r=window.document.getElementById("ref-"+l);r&&(i.innerHTML=r.innerHTML),n.appendChild(i)}),n.innerHTML})}});
</script>
<nav class="column-body page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../submissions/464/index.html" class="pagination-link" aria-label="When the Data Becomes Meta: Quality Control for Digitized Ancient Heritage Collections">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">When the Data Becomes Meta: Quality Control for Digitized Ancient Heritage Collections</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../submissions/468/index.html" class="pagination-link" aria-label="Films as sources and as means of communication for knowledge gained from historical research">
        <span class="nav-page-text">Films as sources and as means of communication for knowledge gained from historical research</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="fade modal" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode code-with-copy markdown"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">submission_id:</span><span class="co"> 465</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> 'Session 4B'</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> On the Historiographic Authority of Machine Learning Systems</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Dominic Weber</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-9265-3388</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: dominic.weber@unibe.ch</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">      - University of Bern</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">      - University of Basel</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - Machine Learning</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - Methodology</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">  - Epistemology</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">  - Facticity</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">  - Evaluation</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> |</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">  The integration of Machine Learning in historical research has significantly altered the approach to sources, data and workflows. Historians now use Machine Learning applications such as Handwritten Text Recognition (HTR) and Natural Language Processing (NLP) to manage large corpora, enhancing research capabilities but also introducing challenges in combining machine-generated and manually created data without propagating errors. The reliability of machine-generated data is a central concern, paralleling issues found in traditional transcription and edition practices. The concept of factoids highlights the fragmentation and recontextualization of data in digital history. Evaluating Machine Learning systems, particularly through tools like CERberus for HTR, emphasises the need for qualitative error analysis to support historical research. The article proposes three strategic directions for digital history: defining clear needs to manage data pragmatically, enhancing transparency to improve data reuse and interoperability, and advancing data criticism and hermeneutics. These directions aim to refine the methods and practices of digital historians, ensuring that Machine Learning outputs are critically assessed and effectively integrated into historical scholarship.</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="an">key-points:</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - Integrating Machine Learning output in historical research requires meticulous evaluation. </span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">  - Factoids can provide a technique for the multifaceted representation of data points.</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">  - Digital History requires new hermeneutical tools suitable for digital data and workflows.</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 07-23-2024</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>Over the last few years, Machine Learning applications became more and more popular in the humanities and social sciences in general, and therefore also in history. Handwritten Text Recognition (HTR) and various tasks of Natural Language Processing (NLP) are now commonly employed in a plethora of research projects of various sizes. Even for PhD projects it is now feasible to research large corpora like serial legal source, which would not be possible entirely by hand. This acceleration of research processes implies fundamental changes to how we think about sources, data, research and workflows.</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>In history, Machine Learning systems are typically used to speed up the production of research data. As the output of these applications is never entirely accurate or correct, this raises the question how historians can use machine generated data together with manually created data without propagating errors and uncertainties to downstream tasks and investigations.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="fu">## Facticity</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>The question of the combined usability of machine-generated and manually generated data is also a question of the reliability or facticity of data. Data generated by humans are not necessarily complete and correct either, as they are a product of human perception. For example, creating transcriptions depends on the respective transcription guidelines and individual text understanding, which can lead to errors. However, we consider transcriptions by experts as correct and use them for historical research. This issue is even more evident in the field of editions. Even very old editions with methodological challenges are valued for their core content. Errors may exist, but they are largely accepted due to the expertise of the editors, treating the output as authorised. This pragmatic approach enables efficient historical research. Historians trust their ability to detect and correct errors during research.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>Francesco Beretta represents data, information, and knowledge as a pyramid: data form the base, historical information (created from data through conceptual models and critical methods) forms the middle, and historical knowledge (produced from historical information through theories, statistical models and heuristics) forms the top <span class="co">[</span><span class="ot">@berettaDonneesOuvertesLiees2023, fig. 3</span><span class="co">]</span>. Interestingly, however, he makes an important distinction regarding digital data: "Digital data does not belong to the epistemic layer of data, but to the layer of information, of which they are the information technical carrier" <span class="co">[</span><span class="ot">Translation: DW. Original Text: "[L]les données numériques n’appartiennent pas à la strate épistémique des données, mais bien à celle de l’information dont elles constituent le support informatique.", @berettaDonneesOuvertesLiees2023, p. 18</span><span class="co">]</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>Andreas Fickers adds that digitization transforms the nature of sources, affecting the concept of the original <span class="co">[</span><span class="ot">@fickersUpdateFuerHermeneutik2020, p. 162</span><span class="co">]</span>. Sources are preprocessed using HTR/OCR and various NLP strategies. The resulting digital data are already processed historical information. This shift from analog to digital means that what we extract from sources is not just given but constructed <span class="co">[</span><span class="ot">@berettaDonneesOuvertesLiees2023, p. 26</span><span class="co">]</span>. Analog historical research, which relies on handwritten archival documents, also depends on transcriptions or editions to conduct research pragmatically; and here, too, data becomes information. The main difference is that with the generation of digital data, the (often linear) structure of sources is typically dissolved in favour of a highly fragmented and hyperconnected structure <span class="co">[</span><span class="ot">For hyperconnectivity see @fickersWhatDoesHistory2022, pp. 51-54; For the underlying concept of hypertextual systems see @landowHypertextCriticalTheory2006, pp. 53-58; for a a more extensive discussion of digital representations of fragmented texts see @weberKlassifizierenVerknupfenAbbilden2021</span><span class="co">]</span>. This is partly due to the way sources are processed into historical information using digital tools and methods, but it is inherently connected with issues of storing, retrieving, and presenting digital data -- in a very technical sense.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>The concept of *factoids* introduced by Michele Pasin and John Bradley, is central to this argument. They define factoids as pieces of information about one or more persons in a primary source. Those factoids are then represented in a semantic network of subject-predicate-object triples <span class="co">[</span><span class="ot">@pasinFactoidbasedProsopographyComputer2015, pp. 89-90</span><span class="co">]</span>. This involves extracting statements from their original context, placing them in a new context, and outsourcing verification to later steps. Therefore, factoids can be contradictory. Francesco Beretta applies this idea to historical science, viewing the aggregation of factoids as a process aiming for the best possible approximation of facticity <span class="co">[</span><span class="ot">@berettaDonneesOuvertesLiees2023, p. 20</span><span class="co">]</span>. The challenge is to verify machine output sufficiently for historical research and to assess the usefulness of the factoid concept. Evaluating machine learning models and their outputs is crucial for this.</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## Qualifying Error Rates</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>Evaluating the output of a machine learning system is not trivial. Models can be evaluated using various calculated scores, which is done continuously during the training process. However, these performance metrics are statistical measures that generally refer to the model and are based on a set of test data. Even the probabilities output by machine learning systems when applied to new data are purely computational figures, only partially suitable for quality assurance. This verification is further complicated by the potentially vast scale of the output. Therefore, historical science must find a pragmatic way to translate statistical evaluation metrics into qualitative statements and identify systematic sources of error.</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>In automatic handwriting recognition, models are typically evaluated using character error rate (CER). These metrics only tell us the percentage of characters or words incorrectly recognised compared to a ground truth. They do not reveal the distribution of these errors, which is important when comparing automatic and manual transcriptions. For detailed HTR model evaluation, CERberus is being developed <span class="co">[</span><span class="ot">@haverals2023cerberus</span><span class="co">]</span>. This tool compares ground truth with HTR output from the same source. Instead of calculating just the character error rate, it breaks down the differences further. Errors are categorised into missing, excess, and incorrectly recognised characters. Additionally, a separate CER is calculated for all characters and Unicode blocks in the text, aggregated into confusion statistics that identify the most frequently confused characters. Confusion plots are generated to show the most common errors for each character. These metrics do not pinpoint specific errors but provide a more precise analysis of the model's behaviour. CERberus cannot evaluate entirely new HTR output without comparison text but is a valuable tool for Digital History, revealing which character forms are often confused and guiding model improvement or post-processing strategies.</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>In other machine learning applications, such as named entity recognition (NER), different metrics are important, requiring detailed error source analysis. Evaluating NER is more complex than HTR because it involves categorizing longer text sections based on context. Precision (how many recognised positives are true positives) and recall (how many actual positives are recognised) are combined into the F1-score to indicate model performance. Fu et al. proposed evaluating NER with a set of eight annotation attributes influencing model performance. These attributes are divided into local properties (entity length, sentence length, unknown word density, entity density) and aggregated attributes (annotation consistency and frequency at the token and entity levels) <span class="co">[</span><span class="ot">@fuInterpretableMultidatasetEvaluation2020, p. 3</span><span class="co">]</span>. Buckets of source points where a model performs particularly well or poorly are created and separately evaluated <span class="co">[</span><span class="ot">@fuInterpretableMultidatasetEvaluation2020, p. 1</span><span class="co">]</span>. This analysis identifies conditions affecting model performance, guiding further training steps and dataset expansion.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>The qualitative error analysis presented here does not solve the question of authorizing machine learning output for historical research. Instead, it provides tools to assess models more precisely and analyse training and test datasets. Such investigations extend the crucial source criticism in historical science to digital datasets and the algorithms and models involved in their creation. This requires historians to expand their traditional methods to include new, less familiar areas.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="fu">## Three Strategic Directions</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>In the following last part of this article, the previously raised questions and problem areas will be consolidated, from which three strategic directions for digital history will be derived. These will be suggestions for how the theory, methodology, and practice of Digital History could evolve to address and mitigate the identified problem areas. The three perspectives should not be viewed in isolation or as mutually exclusive. Instead, they are interdependent and should work together to meet the additional challenges.</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="fu">### Direction 1: Formulating Clear Needs</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>When data is collected or processed into information in the historical research process a certain pragmatism is involved. Ideally, such a project would fully and consistently transcribe the entire collection with the same thoroughness, but in practice, a compromise is often found between completeness, correctness, and pragmatism. Often, for one's own research purposes, it is sufficient to transcribe a source only to the extent that its meaning can be understood. This compromise has not fully transitioned into Digital History. Even if a good CER is achieved, there is pressure to justify how these potential errors are managed in the subsequent research process. This skepticism is not fundamentally bad, and the epistemological consequences of erroneous machine learning output are worthy of discussion. Nonetheless, the resulting text is usually quite readable and usable.</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>Thus, I argue that digital history must more clearly define and communicate its needs. However, it must be remembered that Digital History also faces broader demands. Especially in machine learning-supported research, the demand for data interoperability is rightly emphasised. Incomplete or erroneous datasets are, of course, less reusable by other research projects.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="fu">### Direction 2: Creating Transparency</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>The second direction for digital history is to move towards greater transparency. The issue of reusability and interoperability of datasets from the first strategic direction can be at least partially mitigated by transparency.</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>As Hodel et al. convincingly argued, it is extremely sensible and desirable for projects using HTR to publish their training data. This allows for gradual development towards models that can generalise as broadly as possible <span class="co">[</span><span class="ot">@hodelGeneralModelsHandwritten2021, pp. 7-8</span><span class="co">]</span>. If a CERberus error analysis is conducted for HTR that goes beyond the mere CER, it makes sense to publish this alongside the data and the model. With this information, it is easier to assess whether it might be worthwhile to include this dataset in one's own training material. Similarly, when NER models are published, an extended evaluation according to Fu et al. helps to better assess the performance of a model for one's own dataset.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>Pasin and Bradley, in their prosopographic graph database, indicate the provenance of each data point and who captured it <span class="co">[</span><span class="ot">@pasinFactoidbasedProsopographyComputer2015, 91-92</span><span class="co">]</span>. This principle could also be interesting for Digital History, by indicating in the metadata whether published research data was generated manually or by a machine, ideally with information about the model used and the annotating person for manually generated data. Models provide a confidence estimate with their prediction, indicating how likely the prediction is correct. The most probable prediction would be treated as the first factoid. The second or even third most probable prediction from the systems cloud provide additional factoids that can be incorporate into the source representation. These additional pieces of information can support the further research process by allowing inconsistencies and errors to be better assessed and balanced.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### Direction 3: Data Criticism and Data Hermeneutics</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>The shift to digital history requires an evaluation and adjustment of our hermeneutic methods. This ongoing discourse is not new, and Torsten Hiltmann has identified three broad directions: first, the debate about extending source criticism to data, algorithms, and interfaces; second, the call for computer-assisted methods to support text understanding; and third, the theorization of data hermeneutics, or the "understanding of and with data" <span class="co">[</span><span class="ot">@hiltmann2024, p. 208</span><span class="co">]</span>.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>Even though these discourse strands cannot be sharply separated, the focus here is primarily on data criticism and hermeneutics. The former can fundamentally orient itself towards classical source criticism. Since digital data is not given but constructed, it is crucial to discuss by whom, for what purpose, and how data was generated. This is no easy task, especially when datasets are poorly documented. Therefore, the call for data and model criticism is closely linked to the plea for more transparency in data and model publication.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>In the move towards data hermeneutics, a thorough rethinking of the factoid principle can be fruitful. If, as suggested above, the second or even third most likely predictions of a model are included as factoids in the publication of research data, this opens up additional perspectives on the sources underlying the data. From these new standpoints, the data -- and thus the sources -- can be analyzed and understood more thoroughly. Additionally, this allows for a more informed critique of the data, and extensive transparency also mitigates the "black box" problem of interpretation described by Silke Schwandt <span class="co">[</span><span class="ot">@schwandtOpeningBlackBox2022</span><span class="co">]</span>. If we more precisely describe and reflect on how we generate digital data from sources as historians, we will find that our methods are algorithmic <span class="co">[</span><span class="ot">@schwandtOpeningBlackBox2022, pp. 81-82</span><span class="co">]</span>. This insight can also support the understanding of how machine learning applications work. Data hermeneutics thus requires both a critical reflection of our methods and a more transparent approach to data and metadata.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>:::</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-md-none d-sm-block"><ul><li><a href="https://github.com/digihistch24/book-of-abstracts/edit/main/submissions/465/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/digihistch24/book-of-abstracts/issues/new/choose" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>